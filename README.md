# HumanActivityMonitoring
Our Human Activity Monitoring project uses sensor data and machine learning to automatically recognize and classify human activities in real-time. Ideal for fitness tracking, healthcare, and beyond.

The data set covers acceleration, GPS, gyroscope, light, magnetic field, and sound level data of the activities climbing stairs down and up, jumping, lying, standing, sitting, running/jogging, and walking of fifteen subjects (age 31.9±12.4, height 173.1±6.9, weight 74.1±13.8, eight males and seven females). For each activity, we recorded simultaneously the acceleration of the body positions chest, forearm, head, shin, thigh, upper arm, and waist. Each subject performed each activity roughly 10 minutes except for jumping due to the physical exertion (~1.7 minutes). Concerning male and female, the amount of data is equally distributed. Each movement was recorded by a video camera to facilitate the usage.

15 Subjects
6 Sensors
Video recordings
7 Body positions (Walking, Running, Sitting, Standing, lying, Stairs Up, Stairs Down, Jumping)
